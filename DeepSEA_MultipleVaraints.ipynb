{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad53ebd2",
   "metadata": {},
   "source": [
    "# Expecto Model with multiple variants in input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ddddf2",
   "metadata": {},
   "source": [
    "Working on the Expect model but with each input sequence having a combination of all possible SNPs inside the LD block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c043f",
   "metadata": {},
   "source": [
    "## Working to get sequences by building SNP class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "910553dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing important modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Bio\n",
    "import os\n",
    "from Bio import Entrez, SeqIO\n",
    "import itertools\n",
    "import argparse\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from Multi_specto_class import *\n",
    "from Multi_specto_funcs import *\n",
    "Entrez.email  = \"pradluzog@gmail.com\"\n",
    "Entrez.api_key = \"98ad62666b4bd2dc831f1824727d74d67c08\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50cf31d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading IGAP dataset\n",
    "\n",
    "igap = pd.read_csv('IGAP_stage_1.txt', sep='\\t')\n",
    "#for my mac\n",
    "#igap = pd.read_csv('/Users/pradeep/Downloads/IGAP_stage_1.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1443f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Position</th>\n",
       "      <th>MarkerName</th>\n",
       "      <th>Effect_allele</th>\n",
       "      <th>Non_Effect_allele</th>\n",
       "      <th>Beta</th>\n",
       "      <th>SE</th>\n",
       "      <th>Pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6665069</th>\n",
       "      <td>19</td>\n",
       "      <td>45394969</td>\n",
       "      <td>rs184017</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>0.9704</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6665074</th>\n",
       "      <td>19</td>\n",
       "      <td>45395844</td>\n",
       "      <td>rs34095326</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>1.0392</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6665075</th>\n",
       "      <td>19</td>\n",
       "      <td>45395909</td>\n",
       "      <td>rs34404554</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0536</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6665073</th>\n",
       "      <td>19</td>\n",
       "      <td>45395714</td>\n",
       "      <td>rs157581</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>0.9508</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6665072</th>\n",
       "      <td>19</td>\n",
       "      <td>45395619</td>\n",
       "      <td>rs2075650</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0415</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6665068</th>\n",
       "      <td>19</td>\n",
       "      <td>45394336</td>\n",
       "      <td>rs71352238</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>1.0453</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6665064</th>\n",
       "      <td>19</td>\n",
       "      <td>45390333</td>\n",
       "      <td>rs283815</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>0.9589</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6665065</th>\n",
       "      <td>19</td>\n",
       "      <td>45392254</td>\n",
       "      <td>rs6857</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>1.1610</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6665132</th>\n",
       "      <td>19</td>\n",
       "      <td>45415935</td>\n",
       "      <td>rs7256200</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>1.2812</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6665076</th>\n",
       "      <td>19</td>\n",
       "      <td>45396144</td>\n",
       "      <td>rs11556505</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0651</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Chromosome  Position  MarkerName Effect_allele Non_Effect_allele  \\\n",
       "6665069          19  45394969    rs184017             G                 T   \n",
       "6665074          19  45395844  rs34095326             A                 G   \n",
       "6665075          19  45395909  rs34404554             G                 C   \n",
       "6665073          19  45395714    rs157581             C                 T   \n",
       "6665072          19  45395619   rs2075650             G                 A   \n",
       "6665068          19  45394336  rs71352238             C                 T   \n",
       "6665064          19  45390333    rs283815             G                 A   \n",
       "6665065          19  45392254      rs6857             T                 C   \n",
       "6665132          19  45415935   rs7256200             T                 G   \n",
       "6665076          19  45396144  rs11556505             T                 C   \n",
       "\n",
       "           Beta      SE  Pvalue  \n",
       "6665069  0.9704  0.0208     0.0  \n",
       "6665074  1.0392  0.0258     0.0  \n",
       "6665075  1.0536  0.0228     0.0  \n",
       "6665073  0.9508  0.0205     0.0  \n",
       "6665072  1.0415  0.0226     0.0  \n",
       "6665068  1.0453  0.0227     0.0  \n",
       "6665064  0.9589  0.0213     0.0  \n",
       "6665065  1.1610  0.0226     0.0  \n",
       "6665132  1.2812  0.0262     0.0  \n",
       "6665076  1.0651  0.0231     0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filtering the igap snps \n",
    "igap = igap.sort_values(by = ['Pvalue'], ascending=True)\n",
    "top_10_igap_snps = igap.iloc[0:10,:]\n",
    "top_10_igap_snps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "273edbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a SNP class to perform simple LD filtering duties\n",
    "class SNP:\n",
    "    \n",
    "    def __init__(self,rsid,position,chromosome):\n",
    "        self.rsid = rsid\n",
    "        self.position = position\n",
    "        self.chr = chromosome\n",
    "    \n",
    "\n",
    "        \n",
    "    def check_ld_snps(self,dataset,window = 1000):\n",
    "        start_position = self.position - window + 1\n",
    "        end_position = self.position + window\n",
    "        dataset = dataset[dataset['Chromosome'] == self.chr]\n",
    "        def extract_neighbour_snps(start_position, end_position, dataset):\n",
    "            neighbour_snps = []\n",
    "            for index,row in dataset.iterrows():\n",
    "                if start_position <= dataset.loc[index,'Position'] <= end_position:\n",
    "                    neighbour_snps.append(dataset.loc[index,'MarkerName'])\n",
    "                else:\n",
    "                    continue\n",
    "            return neighbour_snps\n",
    "    \n",
    "        self.snps_in_window = extract_neighbour_snps(start_position,end_position,dataset)\n",
    "        return self.snps_in_window\n",
    "    \n",
    "    def obtain_snp_sequence(self,window = 1000):\n",
    "        start_position = self.position - window +1\n",
    "        end_position = self.position + window\n",
    "        if int(self.chr) < 10:\n",
    "            id_chr = \"\".join([\"NC_00000\",str(self.chr)])\n",
    "        else:\n",
    "            id_chr = \"\".join([\"NC_0000\",str(self.chr)])\n",
    "\n",
    "        handle = Entrez.efetch(db=\"nucleotide\",\n",
    "                        id = id_chr,\n",
    "                        rettype = \"fasta\",\n",
    "                        strand = 1,\n",
    "                        seq_start = start_position,\n",
    "                        seq_stop  = end_position)\n",
    "        record = SeqIO.read(handle,\"fasta\")\n",
    "        self.snp_sequence = str(record.seq)\n",
    "        return self.snp_sequence\n",
    "    \n",
    "    def obtain_all_comb_seq(self,dataset, window = 1000):\n",
    "        \n",
    "        def all_snp_combinations(a):\n",
    "            combinations = []\n",
    "            for k in range(0,len(a)):\n",
    "                t = list(itertools.combinations(a,k+1))\n",
    "                combinations.extend(t)\n",
    "            return combinations\n",
    "        \n",
    "        self.combinations = all_snp_combinations(self.snps_in_window)\n",
    "        comb_names = ['_'.join(x) for x in self.combinations if len(x)> 0]\n",
    "        comb_names.append('_'.join(['Ref',self.rsid]))\n",
    "        combination_dataset = dataset[dataset['MarkerName'].isin(self.snps_in_window)]\n",
    "        sequences = []\n",
    "        \n",
    "        for comb in self.combinations:\n",
    "            seq_to_change = self.snp_sequence\n",
    "            start_position = self.position - window + 1\n",
    "            end_position = self.position + window\n",
    "            for k in range(0,len(comb)):\n",
    "                idx = combination_dataset['MarkerName'] == comb[k]\n",
    "                pos = combination_dataset.loc[idx,'Position']\n",
    "                allele = str(combination_dataset.loc[idx,'Non_Effect_allele'].values[0])\n",
    "                net_pos = int(pos) - int(start_position)\n",
    "                seq_to_change = seq_to_change[:net_pos-1] + allele + seq_to_change[net_pos:]\n",
    "            sequences.append(seq_to_change)\n",
    "        sequences.append(self.snp_sequence)\n",
    "        sequences_named = dict(zip(comb_names,sequences))\n",
    "        return sequences_named\n",
    "                \n",
    "                \n",
    "    def seq_combination(self,dataset,window = 1000):\n",
    "        self.check_ld_snps(dataset,window)\n",
    "        self.obtain_snp_sequence()\n",
    "        self.combination_seq = self.obtain_all_comb_seq(dataset,window)\n",
    "        return self.combination_seq\n",
    "        \n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"The SNP in object is \"+self.rsid\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1dd7a2",
   "metadata": {},
   "source": [
    "## Remodelling Chromatin.py from Expecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd85b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important library calls\n",
    "import argparse\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f46ba8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputing the resources for Expect.py\n",
    "inputsize = 2000\n",
    "batchSize = 32\n",
    "maxshift = 800\n",
    "args_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa2029c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DL model\n",
    "class LambdaBase(nn.Sequential):\n",
    "    def __init__(self, fn, *args):\n",
    "        super(LambdaBase, self).__init__(*args)\n",
    "        self.lambda_func = fn\n",
    "\n",
    "    def forward_prepare(self, input):\n",
    "        output = []\n",
    "        for module in self._modules.values():\n",
    "            output.append(module(input))\n",
    "        return output if output else input\n",
    "\n",
    "class Lambda(LambdaBase):\n",
    "    def forward(self, input):\n",
    "        return self.lambda_func(self.forward_prepare(input))\n",
    "\n",
    "class Beluga(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Beluga, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(4,320,(1, 8)),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(320,320,(1, 8)),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.MaxPool2d((1, 4),(1, 4)),\n",
    "                nn.Conv2d(320,480,(1, 8)),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(480,480,(1, 8)),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.MaxPool2d((1, 4),(1, 4)),\n",
    "                nn.Conv2d(480,640,(1, 8)),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(640,640,(1, 8)),\n",
    "                nn.ReLU(),\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Dropout(0.5),\n",
    "                Lambda(lambda x: x.view(x.size(0),-1)),\n",
    "                nn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(67840,2003)),\n",
    "                nn.ReLU(),\n",
    "                nn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2003,2002)),\n",
    "            ),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "\n",
    "def encodeSeqs(seqs, inputsize=2000):\n",
    "    \"\"\"Convert sequences to 0-1 encoding and truncate to the input size.\n",
    "    The output concatenates the forward and reverse complement sequence\n",
    "    encodings.\n",
    "    Args:\n",
    "        seqs: list of sequences (e.g. produced by fetchSeqs)\n",
    "        inputsize: the number of basepairs to encode in the output\n",
    "    Returns:\n",
    "        numpy array of dimension: (2 x number of sequence) x 4 x inputsize\n",
    "    2 x number of sequence because of the concatenation of forward and reverse\n",
    "    complement sequences.\n",
    "    \"\"\"\n",
    "    seqsnp = np.zeros((len(seqs), 4, inputsize), np.bool_)\n",
    "\n",
    "    mydict = {'A': np.asarray([1, 0, 0, 0]), 'G': np.asarray([0, 1, 0, 0]),\n",
    "            'C': np.asarray([0, 0, 1, 0]), 'T': np.asarray([0, 0, 0, 1]),\n",
    "            'N': np.asarray([0, 0, 0, 0]), 'H': np.asarray([0, 0, 0, 0]),\n",
    "            'a': np.asarray([1, 0, 0, 0]), 'g': np.asarray([0, 1, 0, 0]),\n",
    "            'c': np.asarray([0, 0, 1, 0]), 't': np.asarray([0, 0, 0, 1]),\n",
    "            'n': np.asarray([0, 0, 0, 0]), '-': np.asarray([0, 0, 0, 0])}\n",
    "\n",
    "    n = 0\n",
    "    for line in seqs:\n",
    "        cline = line[int(math.floor(((len(line) - inputsize) / 2.0))):int(math.floor(len(line) - (len(line) - inputsize) / 2.0))]\n",
    "        for i, c in enumerate(cline):\n",
    "            seqsnp[n, :, i] = mydict[c]\n",
    "        n = n + 1\n",
    "\n",
    "    # get the complementary sequences\n",
    "    dataflip = seqsnp[:, ::-1, ::-1]\n",
    "    seqsnp = np.concatenate([seqsnp, dataflip], axis=0)\n",
    "    return seqsnp\n",
    "\n",
    "def get_predicted_diff(snp_comb_seq,inputsize = 2000, batchSize = 32, maxshift = 800, args_cuda = False):\n",
    "    \"\"\"\n",
    "    Function to obtain all the predicted chromatin values for reference and alterante \n",
    "    and find the difference among them for further analysis.\n",
    "    Args:\n",
    "        snp_comb_seq: A dictionary of sequences as string object with A,T,G,C characters\n",
    "                        and keys corresponding to snps and combinations of snps with atleast\n",
    "                        one snp having 'Ref' in the key name to denote reference variant\n",
    "    Return:\n",
    "            A dictionary of matrix size 4000x2002 for the chromatin difference values for each \n",
    "            variant and combination except the reference\n",
    "    \"\"\"\n",
    "    refseqs = [seq for key, seq in snp_comb_seq.items() if 'ref' in key.lower()]\n",
    "    ref_encoded = encodeSeqs(refseqs, inputsize=inputsize).astype(np.float32)\n",
    "\n",
    "    ref_preds = []\n",
    "    for i in range(int(1 + (ref_encoded.shape[0]-1) / batchSize)):\n",
    "        input = torch.from_numpy(ref_encoded[int(i*batchSize):int((i+1)*batchSize),:,:]).unsqueeze(2)\n",
    "        if args_cuda:\n",
    "            input = input.cuda()\n",
    "        ref_preds.append(model.forward(input).cpu().detach().numpy().copy())\n",
    "    ref_preds = np.vstack(ref_preds)\n",
    "    \n",
    "    comb_diff_pred = {}\n",
    "    for comb_seq in snp_comb_seq.keys():\n",
    "\n",
    "        if('Ref' not in comb_seq):\n",
    "\n",
    "            altseqs = [snp_comb_seq[comb_seq]]\n",
    "            alt_encoded = encodeSeqs(altseqs, inputsize=inputsize).astype(np.float32)\n",
    "\n",
    "            alt_preds = []\n",
    "            for i in range(int(1 + (alt_encoded.shape[0]-1) / batchSize)):\n",
    "                input = torch.from_numpy(alt_encoded[int(i*batchSize):int((i+1)*batchSize),:,:]).unsqueeze(2)\n",
    "                if args_cuda:\n",
    "                    input = input.cuda()\n",
    "                alt_preds.append(model.forward(input).cpu().detach().numpy().copy())\n",
    "            alt_preds = np.vstack(alt_preds)\n",
    "\n",
    "            diff = alt_preds - ref_preds\n",
    "            comb_diff_pred[comb_seq] = diff\n",
    "    \n",
    "    \n",
    "    return comb_diff_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "71e90b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Beluga(\n",
       "  (model): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(4, 320, kernel_size=(1, 8), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(320, 320, kernel_size=(1, 8), stride=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): Dropout(p=0.2, inplace=False)\n",
       "      (5): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(320, 480, kernel_size=(1, 8), stride=(1, 1))\n",
       "      (7): ReLU()\n",
       "      (8): Conv2d(480, 480, kernel_size=(1, 8), stride=(1, 1))\n",
       "      (9): ReLU()\n",
       "      (10): Dropout(p=0.2, inplace=False)\n",
       "      (11): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "      (12): Conv2d(480, 640, kernel_size=(1, 8), stride=(1, 1))\n",
       "      (13): ReLU()\n",
       "      (14): Conv2d(640, 640, kernel_size=(1, 8), stride=(1, 1))\n",
       "      (15): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Lambda()\n",
       "      (2): Sequential(\n",
       "        (0): Lambda()\n",
       "        (1): Linear(in_features=67840, out_features=2003, bias=True)\n",
       "      )\n",
       "      (3): ReLU()\n",
       "      (4): Sequential(\n",
       "        (0): Lambda()\n",
       "        (1): Linear(in_features=2003, out_features=2002, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Beluga()\n",
    "model.load_state_dict(torch.load('deepsea.beluga.pth'))\n",
    "model.eval()\n",
    "#model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2291e519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncomb_diff_pred = get_predicted_diff(snp_comb_seq)\\nf = h5py.File(snp_test +'.diff.h5', 'w')\\nkey_names = list(comb_diff_pred.keys())\\nfor i in key_names:\\n    f.create_dataset(i, data=comb_diff_pred[i])\\nf.close()\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "comb_diff_pred = get_predicted_diff(snp_comb_seq)\n",
    "f = h5py.File(snp_test +'.diff.h5', 'w')\n",
    "key_names = list(comb_diff_pred.keys())\n",
    "for i in key_names:\n",
    "    f.create_dataset(i, data=comb_diff_pred[i])\n",
    "f.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e58481",
   "metadata": {},
   "source": [
    "## Running chromatin prediction for top 10 SNPs and its combinations with LD blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a909a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_k = [6,8,7,9,5,4,3,2,1,0]\n",
    "for k in range(2,len(top_10_igap_snps)):\n",
    "    snp_test = top_10_igap_snps.iloc[k,2]\n",
    "    snp_obj = SNP(top_10_igap_snps.iloc[k,2],top_10_igap_snps.iloc[k,1],top_10_igap_snps.iloc[k,0])\n",
    "    snp_comb_seq = snp_obj.seq_combination(igap)\n",
    "    comb_diff_pred = get_predicted_diff(snp_comb_seq)\n",
    "    f = h5py.File(snp_test +'.diff.h5', 'w')\n",
    "    key_names = list(comb_diff_pred.keys())\n",
    "    for i in key_names:\n",
    "        f.create_dataset(i, data=comb_diff_pred[i])\n",
    "    f.close()  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7231e69c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
